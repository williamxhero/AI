{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import count\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS = 2.4\n",
    "VEL = 3.7\n",
    "ANG = 0.27\n",
    "AGV = 3.5\n",
    "\n",
    "class QTable:\n",
    "    def __init__(self):\n",
    "        # state/action/value : Q\n",
    "        # state => (act_0_value, act_1_value)\n",
    "        # Qsa => [Q(s, a0), Q(s, a1)]\n",
    "        # Qsa0 => Qsa[0] => Q(s, a0)\n",
    "        # Qsa1 => Qsa[1] => Q(s, a1)\n",
    "        self.Q = {}\n",
    "        \n",
    "        # state => (act_0_cnt, act_1_cnt)\n",
    "        # Nsa => [N(s, a0), N(s, a1)]\n",
    "        self.N = {}\n",
    "\n",
    "    # set v(s, a)\n",
    "    def set_v(self, state, action, value):\n",
    "        state_k = self._get_state_key(state)\n",
    "        if state_k not in self.Q:\n",
    "            self.Q[state_k] = (0, 0)\n",
    "\n",
    "        Qsa0, Qsa1 = self.Q[state_k]\n",
    "        Qsa = (value if action == 0 else Qsa0, value if action == 1 else Qsa1)\n",
    "        self.Q[state_k] = Qsa\n",
    "        return (Qsa[0], Qsa[1], state_k)\n",
    "\n",
    "    # get (Q(s, a0), Q(s, a1))\n",
    "    def get_v(self, state):\n",
    "        state_k = self._get_state_key(state)\n",
    "        if state_k not in self.Q:\n",
    "            return (0, 0, state_k)\n",
    "        \n",
    "        Qsa = self.Q[state_k]\n",
    "        return (Qsa[0], Qsa[1], state_k)\n",
    "    \n",
    "    def get_cnt(self, state):\n",
    "        state_k = self._get_state_key(state)\n",
    "        if state_k not in self.N:\n",
    "            return (0, 0, state_k)\n",
    "        \n",
    "        Nsa = self.N[state_k]\n",
    "        return (Nsa[0], Nsa[1], state_k)\n",
    "\n",
    "    def inc_cnt(self, state, action):\n",
    "        state_k = self._get_state_key(state)\n",
    "        if state_k not in self.N:\n",
    "            self.N[state_k] = (0, 0)\n",
    "\n",
    "        Nsa0, Nsa1 = self.N[state_k]\n",
    "        Nsa = (Nsa0+1 if action == 0 else Nsa0, Nsa1+1 if action == 1 else Nsa1)\n",
    "        self.N[state_k] = Nsa\n",
    "        return (Nsa[0], Nsa[1], state_k)\n",
    "        \n",
    "    # return maxarg Q(s|a') -> (action, value)\n",
    "    def get_max_action_value(self, state):\n",
    "        state_k = self._get_state_key(state)\n",
    "        a0v, a1v, _ = self.get_v(state)\n",
    "        return (0, a0v) if a0v > a1v else (1, a1v)\n",
    "\n",
    "    def sample(self, size):\n",
    "        state_ks = random.sample(list(self.Q), size) \n",
    "        return [self.Q[k] for k in state_ks]\n",
    "\n",
    "    def _get_state_key(self, state):\n",
    "        pos = state[0] / POS * 10\n",
    "        vel = state[1] / VEL * 10\n",
    "        ang = state[2] / ANG * 10\n",
    "        agv = state[3] / AGV * 10\n",
    "        return '{:.0f},{:.0f},{:.0f},{:.0f}'.format(pos, state[1], state[2], state[3])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.Q)\n",
    "    \n",
    "    def get_dataframe(self):\n",
    "        Qsa = np.array([(k, s[0], s[1]) for k, s in self.Q.items()])\n",
    "        Nsa = np.array([(k, s[0], s[1]) for k, s in self.N.items()])\n",
    "        dfQ = pd.DataFrame(Qsa, columns=['state', 'Q a0', 'Q a1'])\n",
    "        dfQ = dfQ.set_index('state')\n",
    "        \n",
    "        dfN = pd.DataFrame(Nsa, columns=['state', 'N a0', 'N a1'])\n",
    "        dfN = dfN.set_index('state')\n",
    "        \n",
    "        df = dfQ+dfN\n",
    "        return df\n",
    "    \n",
    "q_table = QTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    EPS_START = 0.9  # e-greedy threshold start value\n",
    "    EPS_END = 0.1  # e-greedy threshold end value\n",
    "    EPS_DECAY = 200  # e-greedy threshold decay\n",
    "    AVE = 100        \n",
    "    ALPHA = 0.05\n",
    "    GAMMA = 0.95\n",
    "    MC_GAMMA = 0.3\n",
    "        \n",
    "    def __init__(self):\n",
    "        self.episode_durations = []\n",
    "        self.sar_list = []\n",
    "        self.steps_done = 0\n",
    "        self.cur_state = None\n",
    "        self.plot_kernel = np.ones(self.AVE) / self.AVE\n",
    "        \n",
    "    def select_action(self, state):\n",
    "        self.cur_state = state\n",
    "        self.steps_done += 1\n",
    "        act = q_table.get_max_action_value(state)\n",
    "        return self._e_greedy(act[0])\n",
    "\n",
    "    def _e_greedy(self, act):\n",
    "        sample = random.random()\n",
    "        eps_threshold = self.EPS_END + (self.EPS_START - self.EPS_END) * math.exp(-1. * self.steps_done / self.EPS_DECAY)\n",
    "        if (act is not None) and (sample > eps_threshold):\n",
    "            return act\n",
    "        return random.randrange(2)\n",
    "    \n",
    "    # Temporal Difference\n",
    "    def TD_learn_state(self, next_state, action, reward):\n",
    "\n",
    "        \n",
    "        max_next_value = q_table.get_max_action_value(next_state)[1]\n",
    "        sav = q_table.get_v(self.cur_state)[action]\n",
    "        sav = sav + self.ALPHA * (reward + self.GAMMA * max_next_value - sav)\n",
    "        q_table.set_v(self.cur_state, action, sav)\n",
    "        self.cur_state = next_state\n",
    "    \n",
    "    # Monte carlo\n",
    "    def MC_keep_reward(self, state, action, reward):\n",
    "        self.sar_list.append((state, action, reward))\n",
    "        q_table.inc_cnt(state, action)\n",
    "\n",
    "    def MC_learn_episode(self):\n",
    "        states, actions, rewards = zip(*self.sar_list)\n",
    "        n_rewards = len(rewards)\n",
    "        \n",
    "        for t in range(n_rewards):\n",
    "            s = states[t]\n",
    "            a = actions[t]\n",
    "            Gt = np.array([rewards[p] * self.MC_GAMMA**i for i, p  in enumerate(range(t, n_rewards))]).sum()\n",
    "            sav = q_table.get_v(s)[a]\n",
    "            cnt = q_table.get_cnt(s)[a]\n",
    "            sav += (Gt - sav)/cnt\n",
    "            q_table.set_v(s, a, sav)\n",
    "        \n",
    "        self.sar_list = []\n",
    "\n",
    "    def plot_durations(self, t, rt_plot):\n",
    "        self.episode_durations.append(t)\n",
    "        means = None\n",
    "        \n",
    "        if rt_plot:\n",
    "            plt.figure(2)\n",
    "            plt.clf()\n",
    "            plt.title('Training...')\n",
    "            plt.xlabel('Episode')\n",
    "            plt.ylabel('Duration')\n",
    "            plt.plot(self.episode_durations)\n",
    "            \n",
    "            if len(self.episode_durations) >= self.AVE:\n",
    "                means = np.convolve(self.episode_durations, self.plot_kernel, 'valid')\n",
    "                plt.plot(means)\n",
    "\n",
    "            plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "        \n",
    "        return 0 if means is None else means[-1]\n",
    "        \n",
    "agent = Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 100  # number of episodes\n",
    "MAX_STEP = 200\n",
    "\n",
    "def run_episode(rt_plot):\n",
    "    plt.ion()\n",
    "    \n",
    "    for e in range(EPISODES):\n",
    "        state = env.reset()\n",
    "        mean = 0\n",
    "        for t in count(): \n",
    "            #env.render()\n",
    "            action = agent.select_action(state)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "           \n",
    "            if done and t < MAX_STEP - 1:\n",
    "                reward = -MAX_STEP\n",
    "            \n",
    "            agent.MC_keep_reward(state, action, reward)\n",
    "            #agent.TD_learn_state(state, action, reward)\n",
    "            \n",
    "            state = next_state\n",
    "            \n",
    "            if done:\n",
    "                agent.MC_learn_episode()\n",
    "                mean = agent.plot_durations(t, rt_plot)\n",
    "                break\n",
    "        \n",
    "        if (e+1) % 1000 == 0:\n",
    "            print(\"{2} Episode {0} finished after ave.{1} steps\".format(e, mean, '\\033[92m' if mean>= 195 else '\\033[99m'))\n",
    "  \n",
    "    env.close()\n",
    "    plt.ioff()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-5148e298b20f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mEPISODES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrun_episode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-39ad958e9513>\u001b[0m in \u001b[0;36mrun_episode\u001b[1;34m(rt_plot)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMC_learn_episode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                 \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_durations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrt_plot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-dac347a9098d>\u001b[0m in \u001b[0;36mplot_durations\u001b[1;34m(self, t, rt_plot)\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Episode'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Duration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepisode_durations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpause\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pause a bit so that plots are updated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2759\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2760\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2761\u001b[1;33m     return gca().plot(\n\u001b[0m\u001b[0;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m   2763\u001b[0m         is not None else {}), **kwargs)\n",
      "\u001b[1;32mc:\\users\\willi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1647\u001b[0m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1648\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1649\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1650\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_request_autoscale_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1651\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36madd_line\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m   1848\u001b[0m             \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1850\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1851\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m             \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_line%d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_update_line_limits\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m   1870\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1871\u001b[0m         \"\"\"\n\u001b[1;32m-> 1872\u001b[1;33m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1873\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1874\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\matplotlib\\lines.py\u001b[0m in \u001b[0;36mget_path\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \"\"\"\n\u001b[0;32m   1026\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1027\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1028\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willi\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\matplotlib\\lines.py\u001b[0m in \u001b[0;36mrecache\u001b[1;34m(self, always)\u001b[0m\n\u001b[0;32m    687\u001b[0m                 self.get_clip_on()):\n\u001b[0;32m    688\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_subslice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m             \u001b[0mnanmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnanmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_x_filled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPISODES = 1000\n",
    "%matplotlib\n",
    "run_episode(True)\n",
    "%matplotlib inline\n",
    "\n",
    "agent.plot_durations(0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rewards: 133.31\n",
      "pos -1.4620462119926267 1.5939351126502084\n",
      "vel -2.0472172504582313 2.668858053450312\n",
      "ang -0.25152135311153184 0.257933930763401\n",
      "avel -3.2706476417484476 2.7884078001497468\n"
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    "rewards = []\n",
    "states = []\n",
    "\n",
    "for trails in range(100):\n",
    "    state = env.reset()\n",
    "    reward = 0\n",
    "    for t in count():\n",
    "        #env.render()\n",
    "        action = agent.select_action(state)\n",
    "        state, r, done, _ = env.step(action)\n",
    "        states.append(state)\n",
    "        reward += r\n",
    "        if done:\n",
    "            rewards.append(reward)\n",
    "            #print(reward)\n",
    "            break\n",
    "\n",
    "env.close()\n",
    "print(\"rewards:\", np.average(rewards))\n",
    "pos, vel, ang, avel = zip(*states) \n",
    "print(\"pos\", np.array(pos).min(), np.array(pos).max())\n",
    "print(\"vel\", np.array(vel).min(), np.array(vel).max())\n",
    "print(\"ang\", np.array(ang).min(), np.array(ang).max())\n",
    "print(\"avel\", np.array(avel).min(), np.array(avel).max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
